callbacks:
  checkpoint:
    dirpath: ./checkpoints/all/easy
    filename: lsm-{epoch:02d}
    mode: min
    monitor: val_loss_full
    save_top_k: 1
  early_stopping:
    monitor: val_loss_full
    patience: 1000
  validation_logging:
    plot_path: ./plots/
data:
  batch_size: 32
  equation: ns
  file_path_test_x: /work/mech-ai-scratch/arabeh/data_prep_ns/LDC_NS_2D/processed/easy/all_ldc_test_x.npz
  file_path_test_y: /work/mech-ai-scratch/arabeh/data_prep_ns/LDC_NS_2D/processed/easy/all_ldc_test_y.npz
  file_path_train_x: /work/mech-ai-scratch/arabeh/data_prep_ns/LDC_NS_2D/processed/easy/all_ldc_train_x.npz
  file_path_train_y: /work/mech-ai-scratch/arabeh/data_prep_ns/LDC_NS_2D/processed/easy/all_ldc_train_y.npz
  inputs: sdf
  shuffle: true
  subsample: false
  train_split: 0.8
  type: field
  val_split: 0.2
model:
  in_channels: 2
  log_file: log_lsm_lr=0.001_batch=5.txt
  lr: 0.0001
  num_basis: 16
  num_token: 4
  out_channels: 3
  padding:
  - 0
  - 0
  patch_size:
  - 4
  - 4
  plot_path: plots/lsm/all/easy
  width: 32
sweep_parameters:
  seed:
    values:
    - 0
trainer:
  accelerator: gpu
  devices: 1
  log_every_n_steps: 10
  max_epochs: 200
  seed: 0
