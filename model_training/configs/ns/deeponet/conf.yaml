callbacks:
  checkpoint:
    dirpath: ./checkpoints/
    every_n_epochs: 100
    filename: deeponet-{epoch:02d}
    mode: min
    monitor: val_loss_full
    save_top_k: -1
  dirpath: ./checkpoints/
  early_stopping:
    monitor: val_loss_full
    patience: 1000
  validation_logging:
    plot_path: ./plots/
data:
  batch_size: 64
  equation: ns
  file_path_train_x: /work/mech-ai/rtali/projects/calderon_neural_operators/flowbench-sciml/data/train_capacitance_tensor3d_v1.npy
  file_path_train_y: /work/mech-ai/rtali/projects/calderon_neural_operators/flowbench-sciml/data/train_volume_tensor3d_v1.npy
  file_path_test_x: /work/mech-ai/rtali/projects/calderon_neural_operators/flowbench-sciml/data/test_capacitance_tensor3d_v1.npy
  file_path_test_y: /work/mech-ai/rtali/projects/calderon_neural_operators/flowbench-sciml/data/test_volume_tensor3d_v1.npy
  inputs: sdf
  shuffle: true
  subsample: false
  train_split: 0.8
  type: collocation
  val_split: 0.2
model:
  branch_net_layers:
  - 128
  - 128
  - 128
  input_channels_func: 1
  input_channels_loc: 2
  log_file: log_deeponet.txt
  lr: 0.0001
  modes: 128
  out_channels: 1
  plot_path: ./plots/
  trunk_net_layers:
  - 128
  - 128
  - 128
sweep_parameters:
  seed:
    values:
    - 88
trainer:
  accelerator: gpu
  devices: 1
  log_every_n_steps: 10
  max_epochs: 50
  seed: 88
